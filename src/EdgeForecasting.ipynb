{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from __future__ import division\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.dummy import DummyRegressor\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "from sklearn import preprocessing\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import processData\n",
    "from settings import *\n",
    "from mappings import *\n",
    "from datanetwork import *\n",
    "from bluetoothdata import *\n",
    "from features import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading communication data...\n",
      "Fixing data format...\n",
      "Shape of sms-call data: (537575, 5)\n",
      "Dropping instances where sender and receiver match...\n",
      "Shape of sms-call data: (533121, 5)\n",
      "             DateTime  SenderID  ReceiverID  EventType  EventLength\n",
      "0 2011-08-15 20:03:31     20905       13116          0           15\n",
      "1 2011-08-15 20:03:37     20905       13116          0            0\n",
      "2 2011-08-15 20:47:40     75178       30952          0           39\n",
      "3 2011-08-15 20:47:50     75178       30952          0           23\n",
      "4 2011-08-15 20:48:52     75178       60830          0           14\n",
      "\n",
      "Loading survey data...\n",
      "Fixing data format...\n",
      "Shape of survey dataframe (199, 59)\n",
      "   egoid  age_1  hometown_1               ethnicity_1 gender_1  \\\n",
      "0  97900   18.0         6.0           White/Caucasian   Female   \n",
      "1  97942   19.0         6.0           White/Caucasian     Male   \n",
      "2  31583   18.0         5.0           White/Caucasian   Female   \n",
      "3  10281   18.0         6.0  Mexican American/Chicano     Male   \n",
      "4  31372   18.0         6.0           White/Caucasian     Male   \n",
      "\n",
      "          completed_1             political_1 deathpen_1 marijuana_1  \\\n",
      "0                 NaT                     NaN        NaN         NaN   \n",
      "1 2011-08-17 12:15:00   Slightly conservative   Not sure       Legal   \n",
      "2 2011-08-19 02:55:00   Slightly conservative     Oppose   Not Legal   \n",
      "3 2011-08-15 21:36:00  Extremely conservative      Favor   Not Legal   \n",
      "4 2011-08-20 08:45:00   Slightly conservative      Favor   Not Legal   \n",
      "\n",
      "                                          abortion_1     ...       \\\n",
      "0                                                NaN     ...        \n",
      "1  Law should permit only in rape, incest, or wom...     ...        \n",
      "2  Law should permit only in rape, incest, or wom...     ...        \n",
      "3  Law should permit only in rape, incest, or wom...     ...        \n",
      "4  Law should permited in other cases, but only a...     ...        \n",
      "\n",
      "  euthanasia_5         completed_6            political_6 deathpen_6  \\\n",
      "0          NaN                 NaT                    NaN        NaN   \n",
      "1          NaN                 NaT                    NaN        NaN   \n",
      "2           No 2013-05-06 12:04:40  Slightly conservative   Not sure   \n",
      "3           No 2013-05-04 15:24:30           Conservative      Favor   \n",
      "4          Yes 2013-05-10 20:12:08  Slightly conservative   Not sure   \n",
      "\n",
      "  marijuana_6                                         abortion_6  \\\n",
      "0         NaN                                                NaN   \n",
      "1         NaN                                                NaN   \n",
      "2       Legal  Law should permit only in rape, incest, or wom...   \n",
      "3       Legal  Law should permit only in rape, incest, or wom...   \n",
      "4       Legal                                           Not sure   \n",
      "\n",
      "       homosexual_6      gaymarriage_6   premaritalsex_6 euthanasia_6  \n",
      "0               NaN                NaN               NaN          NaN  \n",
      "1               NaN                NaN               NaN          NaN  \n",
      "2   Sometimes wrong           Disagree   Sometimes wrong           No  \n",
      "3      Always wrong  Strongly disagree  Not wrong at all           No  \n",
      "4  Not wrong at all     Strongly agree  Not wrong at all          Yes  \n",
      "\n",
      "[5 rows x 59 columns]\n",
      "\n",
      "Beginning preprocessing...\n",
      "Number of users who participated in the survey: 199\n",
      "Number of users who answered all surveys for all beliefs: 108\n",
      "Mapping categorical data to numerical data...\n",
      "map\n",
      "after this\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/aastha/anaconda2/lib/python2.7/site-packages/pandas/core/generic.py:3855: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  regex=regex)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/aastha/anaconda2/lib/python2.7/site-packages/pandas/core/generic.py:3660: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._update_inplace(new_data)\n",
      "/Users/aastha/anaconda2/lib/python2.7/site-packages/pandas/core/indexing.py:517: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[item] = s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Extracting corresponding communication network...\n",
      "Number of interactions amongst selected users: 176317\n",
      "Interactions date range: 2011-08-15 20:47:40 - 2014-08-22 00:23:55\n",
      "\n",
      "Building network...\n",
      "Study period: 1\n",
      "Making network from: 2011-08-15 20:47:40 to 2012-01-28 12:19:54\n",
      "Range: >= 2011-08-01 00:00:00 and < 2012-01-01 00:00:00\n",
      "Number of interactions: 28251\n",
      "\n",
      "Study period: 2\n",
      "Making network from: 2012-01-28 12:19:54 to 2012-05-09 09:10:55\n",
      "Range: >= 2012-01-01 00:00:00 and < 2012-05-01 00:00:00\n",
      "Number of interactions: 30017\n",
      "\n",
      "Study period: 3\n",
      "Making network from: 2012-05-09 09:10:55 to 2012-08-20 10:16:29\n",
      "Range: >= 2012-05-01 00:00:00 and < 2012-08-01 00:00:00\n",
      "Number of interactions: 9917\n",
      "\n",
      "Study period: 4\n",
      "Making network from: 2012-08-20 10:16:29 to 2013-01-18 21:25:53\n",
      "Range: >= 2012-08-01 00:00:00 and < 2013-01-01 00:00:00\n",
      "Number of interactions: 34730\n",
      "\n",
      "Study period: 5\n",
      "Making network from: 2013-01-18 21:25:53 to 2013-05-02 09:01:05\n",
      "Range: >= 2013-01-01 00:00:00 and < 2013-05-01 00:00:00\n",
      "Number of interactions: 27043\n",
      "\n",
      "Study period: 6\n",
      "Making network from: 2013-05-02 09:01:05 to 2013-08-31 00:00:00\n",
      "Range: >= 2013-05-01 00:00:00 and < 2013-08-01 00:00:00\n",
      "Size of network: 18836\n"
     ]
    }
   ],
   "source": [
    "survey_df, sms_call_df, communication_time_graphs = processData.processData()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bluetooth_time_graphs, weekend_bluetooth_time_graphs = getBluetoothNetworks(survey_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getTrainTestPairs(time_graphs):\n",
    "    train_pairs = list()\n",
    "    print \"Making Train\"\n",
    "    for t in survey_number[:-2]:\n",
    "        g = time_graphs[t]\n",
    "        print 't =', t, '-> t =', t+1\n",
    "        for eid in g.edges():\n",
    "            uid1 = eid[0]\n",
    "            uid2 = eid[1]\n",
    "            instance = [t, uid1, uid2]\n",
    "            train_pairs.append(instance)\n",
    "    \n",
    "    test_pairs = list()\n",
    "    print \"Making Test\"\n",
    "    for t in survey_number[-2:-1]:\n",
    "        g = time_graphs[t]\n",
    "        print 't =', t, '-> t =', t+1\n",
    "        for eid in g.edges():\n",
    "            uid1 = eid[0]\n",
    "            uid2 = eid[1]\n",
    "            instance = [t, uid1, uid2]\n",
    "            test_pairs.append(instance)\n",
    "\n",
    "    train_pairs = pd.DataFrame(train_pairs, columns=['time', 'uid1', 'uid2'])\n",
    "    test_pairs = pd.DataFrame(test_pairs, columns=['time', 'uid1', 'uid2'])\n",
    "    \n",
    "    return train_pairs, test_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeFeatures(g, i, j):\n",
    "    f1 = getAttributeSim(g, i, j)\n",
    "    f2 = getTriadWeights(g, i, j)\n",
    "    f3 = getbeliefSimilarity(g, i, j)\n",
    "    f4,f5 = social_tie_persistence(g, i, j)\n",
    "    features = [f4, f1, f2, f3, f5]\n",
    "    return features\n",
    "\n",
    "def combinedFeatures(g, bg, i, j):\n",
    "    #common\n",
    "    f1 = getAttributeSim(g, i, j)\n",
    "    f2 = getbeliefSimilarity(g, i, j)    \n",
    "    \n",
    "    #communication network\n",
    "    f3 = getTriadWeights(g, i, j)\n",
    "    f4,f5 = social_tie_persistence(g, i, j)\n",
    "    \n",
    "    #bluetooth network\n",
    "    f6 = getTriadWeights(bg, i, j)\n",
    "    f7,f8 = social_tie_persistence(bg, i, j)\n",
    "    \n",
    "    features = [f4,f1,f2,f3,f5,f6,f7,f8]\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##\n",
    "#1: just communication\n",
    "#2: just bluetooth\n",
    "#3: combined\n",
    "def computePairTrainTest(pairs, bluetooth_time_graphs, communication_time_graphs, weighted, whichNetwork):\n",
    "    print \"weighted:\", weighted\n",
    "    X = list()\n",
    "    y = list()    \n",
    "    for ix, row in pairs.iterrows():\n",
    "        t = row['time']\n",
    "        uid1 = row['uid1']\n",
    "        uid2 = row['uid2']\n",
    "        \n",
    "        g = communication_time_graphs[t]\n",
    "        bg = bluetooth_time_graphs[t]\n",
    "        \n",
    "        next_g = communication_time_graphs[t+1]\n",
    "                \n",
    "        if(whichNetwork == 1):\n",
    "            features = computeFeatures(g, uid1, uid2)\n",
    "        elif(whichNetwork == 2):\n",
    "            features = computeFeatures(bg, uid1, uid2)\n",
    "        elif(whichNetwork == 3):\n",
    "            features = combinedFeatures(g, bg, uid1, uid2)\n",
    "        \n",
    "        X.append(features)\n",
    "        \n",
    "        if next_g.has_edge(uid1, uid2):\n",
    "            if weighted == True:\n",
    "                target = getWeight(next_g[uid1][uid2]['weight'], weight_type)\n",
    "            else:\n",
    "                target = getWeight(next_g[uid1][uid2]['weight'], 'binary')\n",
    "        else:\n",
    "            target = 0\n",
    "        y.append(target)\n",
    "    return X, y\n",
    "        \n",
    "def makePairTrainTest(train_pairs, test_pairs, bluetooth_time_graphs, communication_time_graphs, weighted, whichNetwork):\n",
    "    X_train, y_train = computePairTrainTest(train_pairs, bluetooth_time_graphs, communication_time_graphs, weighted, whichNetwork)\n",
    "    X_test, y_test = computePairTrainTest(test_pairs, bluetooth_time_graphs, communication_time_graphs, weighted, whichNetwork)\n",
    "    \n",
    "    X_train = np.array(X_train)\n",
    "    y_train = np.array(y_train)\n",
    "\n",
    "    X_test = np.array(X_test)\n",
    "    y_test = np.array(y_test)\n",
    "\n",
    "    print \"Train data shape\", X_train.shape, y_train.shape\n",
    "    print \"Test data shape\", X_test.shape, y_test.shape\n",
    "    \n",
    "    return X_train, y_train, X_test, y_test\n",
    "\n",
    "def makeData(X_train, y_train, X_test, y_test):\n",
    "    #make column names\n",
    "    features_names = list()\n",
    "    for ix in range(X_train.shape[1]):\n",
    "        features_names.append('f'+str(ix+1))\n",
    "\n",
    "    target_names = list()\n",
    "    if y_train.ndim == 1:\n",
    "        target_names = ['y']\n",
    "    else:\n",
    "        for ix in range(y_train.shape[1]):\n",
    "            target_names.append('y'+str(ix+1))\n",
    "\n",
    "    column_names = features_names + target_names\n",
    "\n",
    "    #turn lists into dataframes\n",
    "#    print \"Train Data\"\n",
    "    X_train = pd.DataFrame(X_train)\n",
    "    y_train = pd.DataFrame(y_train)\n",
    "    train_df = pd.concat([X_train,y_train],axis=1)\n",
    "    train_df.columns = column_names\n",
    "#    print train_df.head()\n",
    "\n",
    "#    print \"Test Data\"\n",
    "    X_test = pd.DataFrame(X_test)\n",
    "    y_test = pd.DataFrame(y_test)\n",
    "    test_df = pd.concat([X_test,y_test],axis=1)\n",
    "    test_df.columns = column_names\n",
    "#    print test_df.head()\n",
    "    \n",
    "#     #Drop duplicates if any\n",
    "#     print \"Check for duplicates in train data\"\n",
    "#     print \"Train shape before:\", train_df.shape\n",
    "    train_df = pd.DataFrame.drop_duplicates(pd.DataFrame(train_df))\n",
    "#     print \"Train shape after:\", train_df.shape\n",
    "#     print ''\n",
    "\n",
    "#     print \"Test shape before:\", test_df.shape\n",
    "    test_df = pd.DataFrame.drop_duplicates(pd.DataFrame(test_df))\n",
    "#     print \"Test shape after:\", test_df.shape\n",
    "    \n",
    "    # perform min max normalization on the features\n",
    "#     print \"Min Max Normalization...\"\n",
    "#     scaler = preprocessing.MinMaxScaler()\n",
    "#     train_df[features_names] = scaler.fit_transform(train_df[features_names])\n",
    "#     test_df[features_names] = scaler.transform(test_df[features_names])\n",
    "\n",
    "    return train_df, test_df, features_names, target_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fitWeightModel(train_x, train_y, test_x, test_y):\n",
    "    clf =  LinearRegression()\n",
    "    clf.fit(train_x, train_y)\n",
    "    y_hat = clf.predict(test_x)\n",
    "    mse = metrics.mean_squared_error(test_y, y_hat)\n",
    "    print 'MSE %0.2f'% mse\n",
    "    return y_hat\n",
    "\n",
    "def fitClassModel(train_x, train_y, test_x, test_y):\n",
    "    clf =  LogisticRegression(class_weight=\"balanced\", random_state=0)\n",
    "    clf.fit(train_x, train_y)\n",
    "    y_hat = clf.predict(test_x)\n",
    "    f1 = metrics.f1_score(test_y, y_hat, average='weighted')\n",
    "    acc = metrics.accuracy_score(test_y, y_hat)\n",
    "    cm = metrics.confusion_matrix(test_y, y_hat)\n",
    "\n",
    "    #print clf.coef_\n",
    "    print 'F1 %0.2f' % f1\n",
    "#    print 'Accuracy %0.2f' % acc\n",
    "    print \"Confusion matrix\"\n",
    "    print cm\n",
    "    return y_hat\n",
    "\n",
    "def baselineRegressor(train_x, train_y, test_x, test_y):\n",
    "    #Majority\n",
    "    print \"Baseline: Mean Regressor\"\n",
    "    clf1 = DummyRegressor (strategy='mean')\n",
    "    clf1.fit(train_x, train_y)\n",
    "    yhat1 = clf1.predict(test_x)\n",
    "    \n",
    "    mse = metrics.mean_squared_error(test_y, yhat1)\n",
    "    print 'MSE %0.2f'% mse\n",
    "    \n",
    "    #Random\n",
    "    print \"Baseline: Median Regressor\"\n",
    "    clf2 = DummyRegressor (strategy='median')\n",
    "    clf2.fit(train_x, train_y)\n",
    "    yhat2 = clf2.predict(test_x)\n",
    "    \n",
    "    mse = metrics.mean_squared_error(test_y, yhat2)\n",
    "    print 'MSE %0.2f'% mse\n",
    "    \n",
    "    return yhat1, yhat2\n",
    "\n",
    "def baselineClassifier(train_x, train_y, test_x, test_y):\n",
    "#     #Majority\n",
    "#     print \"Baseline: Majority Classifier\"\n",
    "#     clf1 = DummyClassifier(strategy='most_frequent',random_state=0)\n",
    "#     clf1.fit(train_x, train_y)\n",
    "#     yhat1 = clf1.predict(test_x)\n",
    "    \n",
    "#     f1 = metrics.f1_score(test_y, yhat1, average='weighted')\n",
    "#     acc = metrics.accuracy_score(test_y, yhat1)\n",
    "#     cm = metrics.confusion_matrix(test_y, yhat1)\n",
    "\n",
    "#     print 'F1 %0.2f' % f1\n",
    "#     print 'Accuracy %0.2f' % acc\n",
    "#     print \"Confusion matrix\"\n",
    "#     print cm\n",
    "    \n",
    "    #Random\n",
    "    print \"Baseline: Random Classifier\"\n",
    "    clf2 = DummyClassifier(strategy='uniform',random_state=0)\n",
    "    clf2.fit(train_x, train_y)\n",
    "    yhat2 = clf2.predict(test_x)\n",
    "    \n",
    "    f1 = metrics.f1_score(test_y, yhat2, average='weighted')\n",
    "    acc = metrics.accuracy_score(test_y, yhat2)\n",
    "    cm = metrics.confusion_matrix(test_y, yhat2)\n",
    "\n",
    "    print 'F1 %0.2f' % f1\n",
    "#     print 'Accuracy %0.2f' % acc\n",
    "    print \"Confusion matrix\"\n",
    "    print cm\n",
    "    \n",
    "    return yhat2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making Train\n",
      "t = 1 -> t = 2\n",
      "t = 2 -> t = 3\n",
      "t = 3 -> t = 4\n",
      "t = 4 -> t = 5\n",
      "Making Test\n",
      "t = 5 -> t = 6\n",
      "(851, 3)\n",
      "(203, 3)\n"
     ]
    }
   ],
   "source": [
    "train_pairs, test_pairs = getTrainTestPairs(communication_time_graphs)\n",
    "print train_pairs.shape\n",
    "print test_pairs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "Weighted Model: True\n",
      "weighted: True\n",
      "weighted: True\n",
      "Train data shape (851, 5) (851,)\n",
      "Test data shape (203, 5) (203,)\n",
      "['f1', 'f2', 'f3', 'f4', 'f5'] ['y']\n",
      "(833, 6) (194, 6)\n",
      "Min and max edge weight train: 0.0 8.58204416374\n",
      "Min and max edge weight test: 0.0 8.82849412947\n",
      "Model results:\n",
      "MSE 2.50\n",
      "Yesterday results:\n",
      "MSE 2.36\n",
      "Baseline results\n",
      "Baseline: Mean Regressor\n",
      "MSE 4.21\n",
      "Baseline: Median Regressor\n",
      "MSE 4.00\n",
      "****************************************************************************************************\n",
      "2\n",
      "Weighted Model: True\n",
      "weighted: True\n",
      "weighted: True\n",
      "Train data shape (851, 5) (851,)\n",
      "Test data shape (203, 5) (203,)\n",
      "['f1', 'f2', 'f3', 'f4', 'f5'] ['y']\n",
      "(798, 6) (152, 6)\n",
      "Min and max edge weight train: 0.0 8.58204416374\n",
      "Min and max edge weight test: 0.0 8.82849412947\n",
      "Model results:\n",
      "MSE 3.59\n",
      "Yesterday results:\n",
      "MSE 4.12\n",
      "Baseline results\n",
      "Baseline: Mean Regressor\n",
      "MSE 4.21\n",
      "Baseline: Median Regressor\n",
      "MSE 4.11\n",
      "****************************************************************************************************\n",
      "3\n",
      "Weighted Model: True\n",
      "weighted: True\n",
      "weighted: True\n",
      "Train data shape (851, 8) (851,)\n",
      "Test data shape (203, 8) (203,)\n",
      "['f1', 'f2', 'f3', 'f4', 'f5', 'f6', 'f7', 'f8'] ['y']\n",
      "(847, 9) (199, 9)\n",
      "Min and max edge weight train: 0.0 8.58204416374\n",
      "Min and max edge weight test: 0.0 8.82849412947\n",
      "Model results:\n",
      "MSE 2.48\n",
      "Yesterday results:\n",
      "MSE 2.32\n",
      "Baseline results\n",
      "Baseline: Mean Regressor\n",
      "MSE 4.16\n",
      "Baseline: Median Regressor\n",
      "MSE 3.99\n",
      "****************************************************************************************************\n"
     ]
    }
   ],
   "source": [
    "## Based on Communication network\n",
    "##\n",
    "#1: just communication\n",
    "#2: just bluetooth\n",
    "#3: combined\n",
    "\n",
    "#regression\n",
    "weighted = True\n",
    "for whichNetwork in [1,2,3]:\n",
    "    print whichNetwork\n",
    "    print \"Weighted Model:\", weighted\n",
    "    X_train, y_train, X_test, y_test = makePairTrainTest(train_pairs, test_pairs, \n",
    "                                                         bluetooth_time_graphs, \n",
    "                                                         communication_time_graphs, \n",
    "                                                         weighted, whichNetwork)\n",
    "    train_df, test_df, features_names, target_names = makeData(X_train, y_train, X_test, y_test)\n",
    "    print features_names, target_names\n",
    "    \n",
    "    print train_df.shape, test_df.shape\n",
    "\n",
    "    print \"Min and max edge weight train:\", train_df.y.min(),train_df.y.max()\n",
    "    print \"Min and max edge weight test:\", test_df.y.min(),test_df.y.max()\n",
    "\n",
    "    print \"Model results:\"\n",
    "    fitWeightModel(train_df[features_names], train_df[target_names], test_df[features_names], test_df[target_names])\n",
    "            \n",
    "    print \"Yesterday results:\"\n",
    "    fitWeightModel(train_df.f1.values.reshape(-1, 1), train_df[target_names], test_df.f1.values.reshape(-1, 1), test_df[target_names])\n",
    "    \n",
    "    print \"Baseline results\"\n",
    "    baselineRegressor(train_df[features_names], train_df[target_names], test_df[features_names], test_df[target_names])\n",
    "    \n",
    "    print \"*\"*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "Weighted Model: False\n",
      "weighted: False\n",
      "weighted: False\n",
      "Train data shape (851, 5) (851,)\n",
      "Test data shape (203, 5) (203,)\n",
      "['f1', 'f2', 'f3', 'f4', 'f5'] ['y']\n",
      "(827, 6) (193, 6)\n",
      "Train Distribution: Counter({1: 534, 0: 293})\n",
      "Test Distribution: Counter({1: 107, 0: 86})\n",
      "Model results:\n",
      "F1 0.76\n",
      "Confusion matrix\n",
      "[[65 21]\n",
      " [25 82]]\n",
      "Train Distribution: Counter({1: 534, 0: 293})\n",
      "Test Distribution: Counter({1: 107, 0: 86})\n",
      "Yesterday results:\n",
      "F1 0.75\n",
      "Confusion matrix\n",
      "[[63 23]\n",
      " [25 82]]\n",
      "Train Distribution: Counter({1: 534, 0: 293})\n",
      "Test Distribution: Counter({1: 107, 0: 86})\n",
      "Baseline results:\n",
      "Baseline: Random Classifier\n",
      "F1 0.52\n",
      "Confusion matrix\n",
      "[[44 42]\n",
      " [50 57]]\n",
      "****************************************************************************************************\n",
      "2\n",
      "Weighted Model: False\n",
      "weighted: False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/aastha/anaconda2/lib/python2.7/site-packages/sklearn/utils/validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weighted: False\n",
      "Train data shape (851, 5) (851,)\n",
      "Test data shape (203, 5) (203,)\n",
      "['f1', 'f2', 'f3', 'f4', 'f5'] ['y']\n",
      "(743, 6) (134, 6)\n",
      "Train Distribution: Counter({1: 471, 0: 272})\n",
      "Test Distribution: Counter({1: 78, 0: 56})\n",
      "Model results:\n",
      "F1 0.61\n",
      "Confusion matrix\n",
      "[[31 25]\n",
      " [27 51]]\n",
      "Train Distribution: Counter({1: 471, 0: 272})\n",
      "Test Distribution: Counter({1: 78, 0: 56})\n",
      "Yesterday results:\n",
      "F1 0.46\n",
      "Confusion matrix\n",
      "[[29 27]\n",
      " [45 33]]\n",
      "Train Distribution: Counter({1: 471, 0: 272})\n",
      "Test Distribution: Counter({1: 78, 0: 56})\n",
      "Baseline results:\n",
      "Baseline: Random Classifier\n",
      "F1 0.57\n",
      "Confusion matrix\n",
      "[[29 27]\n",
      " [31 47]]\n",
      "****************************************************************************************************\n",
      "3\n",
      "Weighted Model: False\n",
      "weighted: False\n",
      "weighted: False\n",
      "Train data shape (851, 8) (851,)\n",
      "Test data shape (203, 8) (203,)\n",
      "['f1', 'f2', 'f3', 'f4', 'f5', 'f6', 'f7', 'f8'] ['y']\n",
      "(845, 9) (199, 9)\n",
      "Train Distribution: Counter({1: 538, 0: 307})\n",
      "Test Distribution: Counter({1: 109, 0: 90})\n",
      "Model results:\n",
      "F1 0.72\n",
      "Confusion matrix\n",
      "[[64 26]\n",
      " [29 80]]\n",
      "Train Distribution: Counter({1: 538, 0: 307})\n",
      "Test Distribution: Counter({1: 109, 0: 90})\n",
      "Yesterday results:\n",
      "F1 0.75\n",
      "Confusion matrix\n",
      "[[67 23]\n",
      " [27 82]]\n",
      "Train Distribution: Counter({1: 538, 0: 307})\n",
      "Test Distribution: Counter({1: 109, 0: 90})\n",
      "Baseline results:\n",
      "Baseline: Random Classifier\n",
      "F1 0.48\n",
      "Confusion matrix\n",
      "[[42 48]\n",
      " [56 53]]\n",
      "****************************************************************************************************\n"
     ]
    }
   ],
   "source": [
    "weighted = False\n",
    "for whichNetwork in [1,2,3]:\n",
    "    print whichNetwork\n",
    "    print \"Weighted Model:\", weighted\n",
    "    X_train, y_train, X_test, y_test = makePairTrainTest(train_pairs, test_pairs, \n",
    "                                                         bluetooth_time_graphs, \n",
    "                                                         communication_time_graphs, \n",
    "                                                         weighted, whichNetwork)\n",
    "    train_df, test_df, features_names, target_names = makeData(X_train, y_train, X_test, y_test)\n",
    "    print features_names, target_names\n",
    "    \n",
    "    print train_df.shape, test_df.shape\n",
    "    \n",
    "    print \"Train Distribution:\", Counter(train_df.y)\n",
    "    print \"Test Distribution:\", Counter(test_df.y)\n",
    "\n",
    "    print \"Model results:\"\n",
    "    fitClassModel(train_df[features_names], train_df[target_names], test_df[features_names], test_df[target_names])\n",
    "\n",
    "    print \"Train Distribution:\", Counter(train_df.y)\n",
    "    print \"Test Distribution:\", Counter(test_df.y)\n",
    "\n",
    "    print \"Yesterday results:\"\n",
    "    fitClassModel(train_df.f1.values.reshape(-1, 1), train_df[target_names], test_df.f1.values.reshape(-1, 1), test_df[target_names])\n",
    "\n",
    "    print \"Train Distribution:\", Counter(train_df.y)\n",
    "    print \"Test Distribution:\", Counter(test_df.y)\n",
    "\n",
    "    print \"Baseline results:\"\n",
    "    baselineClassifier(train_df[features_names], train_df.y, test_df[features_names], test_df.y)\n",
    "    print \"*\"*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "Weighted Model: True\n",
      "weighted: True\n",
      "weighted: True\n",
      "Train data shape (851, 5) (851,)\n",
      "Test data shape (203, 5) (203,)\n",
      "['f1', 'f2', 'f3', 'f4', 'f5'] ['y']\n",
      "(833, 6) (194, 6)\n",
      "Min and max edge weight train: 0.0 8.58204416374\n",
      "Min and max edge weight test: 0.0 8.82849412947\n",
      "Model results:\n",
      "MSE 2.50\n",
      "Yesterday results:\n",
      "MSE 2.36\n",
      "Baseline results\n",
      "Baseline: Mean Regressor\n",
      "MSE 4.21\n",
      "Baseline: Median Regressor\n",
      "MSE 4.00\n",
      "****************************************************************************************************\n",
      "2\n",
      "Weighted Model: True\n",
      "weighted: True\n",
      "weighted: True\n",
      "Train data shape (851, 5) (851,)\n",
      "Test data shape (203, 5) (203,)\n",
      "['f1', 'f2', 'f3', 'f4', 'f5'] ['y']\n",
      "(783, 6) (150, 6)\n",
      "Min and max edge weight train: 0.0 8.58204416374\n",
      "Min and max edge weight test: 0.0 8.82849412947\n",
      "Model results:\n",
      "MSE 3.34\n",
      "Yesterday results:\n",
      "MSE 4.09\n",
      "Baseline results\n",
      "Baseline: Mean Regressor\n",
      "MSE 4.26\n",
      "Baseline: Median Regressor\n",
      "MSE 4.13\n",
      "****************************************************************************************************\n",
      "3\n",
      "Weighted Model: True\n",
      "weighted: True\n",
      "weighted: True\n",
      "Train data shape (851, 8) (851,)\n",
      "Test data shape (203, 8) (203,)\n",
      "['f1', 'f2', 'f3', 'f4', 'f5', 'f6', 'f7', 'f8'] ['y']\n",
      "(844, 9) (197, 9)\n",
      "Min and max edge weight train: 0.0 8.58204416374\n",
      "Min and max edge weight test: 0.0 8.82849412947\n",
      "Model results:\n",
      "MSE 2.35\n",
      "Yesterday results:\n",
      "MSE 2.33\n",
      "Baseline results\n",
      "Baseline: Mean Regressor\n",
      "MSE 4.19\n",
      "Baseline: Median Regressor\n",
      "MSE 4.01\n",
      "****************************************************************************************************\n"
     ]
    }
   ],
   "source": [
    "## Based on Weekend network\n",
    "##\n",
    "#1: just communication\n",
    "#2: just bluetooth\n",
    "#3: combined\n",
    "\n",
    "#regression\n",
    "weighted = True\n",
    "for whichNetwork in [1,2,3]:\n",
    "    print whichNetwork\n",
    "    print \"Weighted Model:\", weighted\n",
    "    X_train, y_train, X_test, y_test = makePairTrainTest(train_pairs, test_pairs, \n",
    "                                                         weekend_bluetooth_time_graphs, \n",
    "                                                         communication_time_graphs, \n",
    "                                                         weighted, whichNetwork)\n",
    "    train_df, test_df, features_names, target_names = makeData(X_train, y_train, X_test, y_test)\n",
    "    print features_names, target_names\n",
    "    \n",
    "    print train_df.shape, test_df.shape\n",
    "\n",
    "    print \"Min and max edge weight train:\", train_df.y.min(),train_df.y.max()\n",
    "    print \"Min and max edge weight test:\", test_df.y.min(),test_df.y.max()\n",
    "\n",
    "    print \"Model results:\"\n",
    "    fitWeightModel(train_df[features_names], train_df[target_names], test_df[features_names], test_df[target_names])\n",
    "            \n",
    "    print \"Yesterday results:\"\n",
    "    fitWeightModel(train_df.f1.values.reshape(-1, 1), train_df[target_names], test_df.f1.values.reshape(-1, 1), test_df[target_names])\n",
    "    \n",
    "    print \"Baseline results\"\n",
    "    baselineRegressor(train_df[features_names], train_df[target_names], test_df[features_names], test_df[target_names])\n",
    "    \n",
    "    print \"*\"*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "Weighted Model: False\n",
      "weighted: False\n",
      "weighted: False\n",
      "Train data shape (851, 5) (851,)\n",
      "Test data shape (203, 5) (203,)\n",
      "['f1', 'f2', 'f3', 'f4', 'f5'] ['y']\n",
      "(827, 6) (193, 6)\n",
      "Train Distribution: Counter({1: 534, 0: 293})\n",
      "Test Distribution: Counter({1: 107, 0: 86})\n",
      "Model results:\n",
      "F1 0.76\n",
      "Confusion matrix\n",
      "[[65 21]\n",
      " [25 82]]\n",
      "Train Distribution: Counter({1: 534, 0: 293})\n",
      "Test Distribution: Counter({1: 107, 0: 86})\n",
      "Yesterday results:\n",
      "F1 0.75\n",
      "Confusion matrix\n",
      "[[63 23]\n",
      " [25 82]]\n",
      "Train Distribution: Counter({1: 534, 0: 293})\n",
      "Test Distribution: Counter({1: 107, 0: 86})\n",
      "Baseline results:\n",
      "Baseline: Random Classifier\n",
      "F1 0.52\n",
      "Confusion matrix\n",
      "[[44 42]\n",
      " [50 57]]\n",
      "****************************************************************************************************\n",
      "2\n",
      "Weighted Model: False\n",
      "weighted: False\n",
      "weighted: False\n",
      "Train data shape (851, 5) (851,)\n",
      "Test data shape (203, 5) (203,)\n",
      "['f1', 'f2', 'f3', 'f4', 'f5'] ['y']\n",
      "(726, 6) (131, 6)\n",
      "Train Distribution: Counter({1: 463, 0: 263})\n",
      "Test Distribution: Counter({1: 76, 0: 55})\n",
      "Model results:\n",
      "F1 0.65\n",
      "Confusion matrix\n",
      "[[32 23]\n",
      " [23 53]]\n",
      "Train Distribution: Counter({1: 463, 0: 263})\n",
      "Test Distribution: Counter({1: 76, 0: 55})\n",
      "Yesterday results:\n",
      "F1 0.48\n",
      "Confusion matrix\n",
      "[[31 24]\n",
      " [44 32]]\n",
      "Train Distribution: Counter({1: 463, 0: 263})\n",
      "Test Distribution: Counter({1: 76, 0: 55})\n",
      "Baseline results:\n",
      "Baseline: Random Classifier\n",
      "F1 0.54\n",
      "Confusion matrix\n",
      "[[27 28]\n",
      " [32 44]]\n",
      "****************************************************************************************************\n",
      "3\n",
      "Weighted Model: False\n",
      "weighted: False\n",
      "weighted: False\n",
      "Train data shape (851, 8) (851,)\n",
      "Test data shape (203, 8) (203,)\n",
      "['f1', 'f2', 'f3', 'f4', 'f5', 'f6', 'f7', 'f8'] ['y']\n",
      "(842, 9) (196, 9)\n",
      "Train Distribution: Counter({1: 538, 0: 304})\n",
      "Test Distribution: Counter({1: 107, 0: 89})\n",
      "Model results:\n",
      "F1 0.75\n",
      "Confusion matrix\n",
      "[[66 23]\n",
      " [27 80]]\n",
      "Train Distribution: Counter({1: 538, 0: 304})\n",
      "Test Distribution: Counter({1: 107, 0: 89})\n",
      "Yesterday results:\n",
      "F1 0.76\n",
      "Confusion matrix\n",
      "[[66 23]\n",
      " [25 82]]\n",
      "Train Distribution: Counter({1: 538, 0: 304})\n",
      "Test Distribution: Counter({1: 107, 0: 89})\n",
      "Baseline results:\n",
      "Baseline: Random Classifier\n",
      "F1 0.49\n",
      "Confusion matrix\n",
      "[[42 47]\n",
      " [54 53]]\n",
      "****************************************************************************************************\n"
     ]
    }
   ],
   "source": [
    "weighted = False\n",
    "for whichNetwork in [1,2,3]:\n",
    "    print whichNetwork\n",
    "    print \"Weighted Model:\", weighted\n",
    "    X_train, y_train, X_test, y_test = makePairTrainTest(train_pairs, test_pairs, \n",
    "                                                         weekend_bluetooth_time_graphs, \n",
    "                                                         communication_time_graphs, \n",
    "                                                         weighted, whichNetwork)\n",
    "    train_df, test_df, features_names, target_names = makeData(X_train, y_train, X_test, y_test)\n",
    "    print features_names, target_names\n",
    "    \n",
    "    print train_df.shape, test_df.shape\n",
    "    \n",
    "    print \"Train Distribution:\", Counter(train_df.y)\n",
    "    print \"Test Distribution:\", Counter(test_df.y)\n",
    "\n",
    "    print \"Model results:\"\n",
    "    fitClassModel(train_df[features_names], train_df[target_names], test_df[features_names], test_df[target_names])\n",
    "\n",
    "    print \"Train Distribution:\", Counter(train_df.y)\n",
    "    print \"Test Distribution:\", Counter(test_df.y)\n",
    "\n",
    "    print \"Yesterday results:\"\n",
    "    fitClassModel(train_df.f1.values.reshape(-1, 1), train_df[target_names], test_df.f1.values.reshape(-1, 1), test_df[target_names])\n",
    "\n",
    "    print \"Train Distribution:\", Counter(train_df.y)\n",
    "    print \"Test Distribution:\", Counter(test_df.y)\n",
    "\n",
    "    print \"Baseline results:\"\n",
    "    baselineClassifier(train_df[features_names], train_df.y, test_df[features_names], test_df.y)\n",
    "    print \"*\"*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
